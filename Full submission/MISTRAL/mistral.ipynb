{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9496930,"sourceType":"datasetVersion","datasetId":5779123},{"sourceId":5112,"sourceType":"modelInstanceVersion","modelInstanceId":3900,"modelId":1902}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install -q -U bitsandbytes","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-29T17:29:53.245839Z","iopub.execute_input":"2024-09-29T17:29:53.246411Z","iopub.status.idle":"2024-09-29T17:30:47.092792Z","shell.execute_reply.started":"2024-09-29T17:29:53.246385Z","shell.execute_reply":"2024-09-29T17:30:47.091594Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM","metadata":{"execution":{"iopub.status.busy":"2024-09-29T17:30:51.299597Z","iopub.execute_input":"2024-09-29T17:30:51.300446Z","iopub.status.idle":"2024-09-29T17:30:54.975890Z","shell.execute_reply.started":"2024-09-29T17:30:51.300410Z","shell.execute_reply":"2024-09-29T17:30:54.975123Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"What is the approximate number of luffas that a fully grown luffa tree can produce in a single growing season?\"},\n    {\"role\": \"assistant\", \"content\": \"A mature luffa tree can typically produce several clusters of fruit throughout the growing season. Each cluster can contain several luffas, and a fully grown luffa tree may produce between 10 to 20 clusters of fruit in a single growing season.\"},\n    {\"role\": \"user\", \"content\": \"Let's go plant some luffa trees together\"}\n]\nmodel_name = '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\nencodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\nmodel_inputs = encodeds\ngenerated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\ndecoded = tokenizer.batch_decode(generated_ids)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-29T17:31:56.757029Z","iopub.execute_input":"2024-09-29T17:31:56.757842Z","iopub.status.idle":"2024-09-29T17:34:45.285654Z","shell.execute_reply.started":"2024-09-29T17:31:56.757807Z","shell.execute_reply":"2024-09-29T17:34:45.284836Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0f6436a1e2549fc95cce36e143edb41"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1935: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-29T17:37:25.442835Z","iopub.execute_input":"2024-09-29T17:37:25.443547Z","iopub.status.idle":"2024-09-29T17:37:25.448629Z","shell.execute_reply.started":"2024-09-29T17:37:25.443486Z","shell.execute_reply":"2024-09-29T17:37:25.447617Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<s> [INST] What is the approximate number of luffas that a fully grown luffa tree can produce in a single growing season? [/INST]A mature luffa tree can typically produce several clusters of fruit throughout the growing season. Each cluster can contain several luffas, and a fully grown luffa tree may produce between 10 to 20 clusters of fruit in a single growing season.</s>  [INST] Let's go plant some luffa trees together [/INST] Sure! Luffa trees are typically easy to grow and thrive in a variety of soil types and climates. To plant luffa trees, you'll need to follow these general steps:\n\n1. Choose a location: Select an area where the tree will receive ample sunlight and have enough space to grow.\n2. Prepare the soil: Loosen the soil with a garden fork to about 12 inches deep, as luffa trees require well-drained soil.\n3. Plant the seeds: Luffa seeds are typically planted about 1 inch deep and 1-2 feet apart in rows that are about 2-3 feet apart.\n4. Care for the seedlings: Water the seedlings regularly and fertilize them as needed, following the specific fertilizer recommendations for luffa trees.\n5. Prune the tree: Once the tree has grown to a height of 6-8 feet, begin pruning to encourage branching and prevent it from becoming too leggy.\n6. Watch for luffas: As the fruit develops on the branches, it will typically grow to a length of 2-10 feet. Pick them when they reach the desired size and ripeness.\n\nBy following these steps, you should be able to grow luffa trees successfully and enjoy the delicious and versatile fruit that they produce.</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U langchain-community","metadata":{"execution":{"iopub.status.busy":"2024-09-29T17:48:03.291364Z","iopub.execute_input":"2024-09-29T17:48:03.292298Z","iopub.status.idle":"2024-09-29T17:48:18.197913Z","shell.execute_reply.started":"2024-09-29T17:48:03.292260Z","shell.execute_reply":"2024-09-29T17:48:18.196910Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.17)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.8.4)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.0)\nRequirement already satisfied: langchain<0.4.0,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.1)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.6)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.129)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.23.5)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.31.0)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.2.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\nCollecting pydantic<3.0.0,>=2.7.4 (from langchain<0.4.0,>=0.3.1->langchain-community)\n  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (2.0.2)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.1.1)\nInstalling collected packages: pydantic, pydantic-settings, langchain-community\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.3.0\n    Uninstalling pydantic-2.3.0:\n      Successfully uninstalled pydantic-2.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastapi 0.98.0 requires pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4, but you have pydantic 2.9.2 which is incompatible.\nydata-profiling 4.3.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.9.2 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-community-0.3.1 pydantic-2.9.2 pydantic-settings-2.5.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Credit:\n - Adapted from https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1","metadata":{}},{"cell_type":"code","source":"\n# Import necessary libraries\nimport time  # Import time module for tracking time\nfrom langchain.chains import RetrievalQA\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import LlamaCpp\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.document_loaders import PyPDFDirectoryLoader\n\n# Start tracking the time for loading PDFs\nstart_time = time.time()\n\n# Load PDF documents from the specified directory\nloader = PyPDFDirectoryLoader(\"/kaggle/input/ncert-dataset\")  # Change this path to your uploaded PDF folder\ndata = loader.load()\n\n# Record the time taken to load PDFs\npdf_load_time = time.time() - start_time\nprint(f\"Time taken to load PDFs: {pdf_load_time:.2f} seconds\")\n\n# Step 05: Split the Extracted Data into Text Chunks\nstart_time = time.time()  # Start time tracking for text splitting\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\ntext_chunks = text_splitter.split_documents(data)\n\n# Record the time taken to split text\nsplit_time = time.time() - start_time\nprint(f\"Time taken to split text: {split_time:.2f} seconds\")\n\n# Step 06: Download the Embeddings\nstart_time = time.time()  # Start time tracking for embeddings\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n\n# Step 08: Create Embeddings for each of the Text Chunk\nvector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n\n# Record the time taken for embedding generation\nembedding_time = time.time() - start_time\nprint(f\"Time taken to generate embeddings: {embedding_time:.2f} seconds\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T17:51:07.771914Z","iopub.execute_input":"2024-09-29T17:51:07.772718Z","iopub.status.idle":"2024-09-29T17:51:14.559682Z","shell.execute_reply.started":"2024-09-29T17:51:07.772682Z","shell.execute_reply":"2024-09-29T17:51:14.558711Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Time taken to load PDFs: 5.77 seconds\nTime taken to split text: 0.00 seconds\nTime taken to generate embeddings: 1.00 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\n# Change this to the model path or name from Hugging Face\nmodel_name = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"  # Use a valid path or model name from Hugging Face\n\n# Load tokenizer and model from Hugging Face\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n\n# Tokenize input\nmessages = [{\"role\": \"user\", \"content\": \"What is linear sound?\"}]\ninput_ids = tokenizer.encode(messages[0]['content'], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate text response\nwith torch.no_grad():\n    outputs = model.generate(input_ids, max_new_tokens=50)\n\n# Decode output\ndecoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(decoded_output)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T17:54:55.724298Z","iopub.execute_input":"2024-09-29T17:54:55.724935Z","iopub.status.idle":"2024-09-29T17:55:28.387046Z","shell.execute_reply.started":"2024-09-29T17:54:55.724902Z","shell.execute_reply":"2024-09-29T17:55:28.385988Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a56e751949a4580ba51a0f50f3d7091"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What is linear sound?\nA: Linear sound is a type of sound that is produced by vibrations that move in a straight line. This type of sound is often described as being clear and crisp, and can be heard in a variety of environments, including music\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.vectorstores import FAISS\n\n# Step 1: Load Pre-trained LLM (same as before)\nmodel_name = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"  # Change to your model path or Hugging Face model name\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T18:15:49.377385Z","iopub.execute_input":"2024-09-29T18:15:49.378161Z","iopub.status.idle":"2024-09-29T18:17:59.505124Z","shell.execute_reply.started":"2024-09-29T18:15:49.378127Z","shell.execute_reply":"2024-09-29T18:17:59.504327Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"656b29f84e2543d1ae4922dda7b5d41b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\nfrom langchain.llms import HuggingFacePipeline\n\nhf_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens = 2000)\n# gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=200)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\n# Step 4: Create a retriever from the FAISS vector store\nretriever = vector_store.as_retriever(search_kwargs={\"k\": 2})  # Retrieve top 2 relevant documents\n\n# Step 5: Set up the Retrieval-Augmented Generation (RAG) chain using the wrapped LLM\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    retriever=retriever,\n    chain_type=\"stuff\",  # Use \"stuff\" or other types depending on your needs\n    return_source_documents=True  # Optionally return retrieved documents\n)\n\n# Step 6: Query the RAG system\nquery = \"What is linear sound?\"  # Example query from user\n\n# You may want to set `max_length` or `max_new_tokens` in your pipeline call\nresult = qa_chain({\"query\": query, \"max_new_tokens\": 10000})  # Set max_new_tokens as needed\n\n# Print the generated response\nprint(\"Generated Response:\", result['result'])\n\n# Optionally, print the retrieved documents (for debug purposes)\nfor i, doc in enumerate(result['source_documents']):\n    print(f\"\\nRetrieved Document {i + 1}:\\n\", doc.page_content)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T18:17:59.508600Z","iopub.execute_input":"2024-09-29T18:17:59.509350Z","iopub.status.idle":"2024-09-29T18:18:08.785915Z","shell.execute_reply.started":"2024-09-29T18:17:59.509320Z","shell.execute_reply":"2024-09-29T18:18:08.784813Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Response: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\nSOUND 131How the brain interprets the frequency\nof an emitted sound is called its pitch. The\nfaster the vibration of the source, the\nhigher is the frequency and the higher is\nthe pitch, as shown in Fig. 11.7. Thus, a\nhigh pitch sound corresponds to more\nnumber of compressions and rarefactions\npassing a fixed point per unit time.\nObjects of different sizes and conditions\nvibrate at different frequencies to produce\nsounds of different pitch.\nThe magnitude of the maximum\ndisturbance in the medium on either side of\nthe mean value is called the amplitude of the\nwave. It is usually represented by the letter A,as shown in Fig. 11.6(c). For sound its unit\nwill be that of density or pressure.\nThe loudness or softness of a sound is\ndetermined basically by its amplitude. The\namplitude of the sound wave depends upon\nthe force with which an object is made to\nvibrate. If we strike a table lightly, we hear a\nsoft sound because we produce a sound wavedensity of the medium oscillates between a\nmaximum value and a minimum value. The\nchange in density from the maximum value\nto the minimum value, then again to the\nmaximum value, makes one complete\noscillation. The number of such oscillations\nper unit time is the frequency of the sound\nwave. If we can count the number of the\ncompressions or rarefactions that cross us\nper unit time, we will get the frequency of\nthe sound wave. It is usually represented by\nν (Greek letter , nu). Its SI unit is hertz\n(symbol, Hz).\nThe time taken by two consecutive\ncompressions or rarefactions to cross a fixed\npoint is called the time period of the wave. In\nother words, we can say that the time taken\nfor one complete oscillation is called the time\nperiod of the sound wave. It is represented by\nthe symbol T. Its SI unit is second (s).\nFrequency and time period are related as\nfollows:\n A violin and a flute may both be played at\nthe same time in an orchestra. Both sounds\ntravel through the same medium, that is, air\nand arrive at our ear at the same time. Both\nsounds travel at the same speed irrespective\nof the source. But the sounds we receive are\ndifferent. This is due to the different\ncharacteristics associated with the sound.\nPitch is one of the characteristics.=1vTFig. 11.7:  Low pitch sound has low frequency and\nhigh pitch of sound has high frequency.\nFig. 11.8: Soft sound has small amplitude and\nlouder sound has large amplitude.\nRationalised 2023-24\n\nSCIENCE 128the vibrating object to the ear . A particle of\nthe medium in contact with the vibrating\nobject is first displaced fr om its equilibrium\nposition. It then exerts a for ce on the adjacent\nparticle. As a r esult of which the adjacent\nparticle gets displaced fr om its position of\nrest. After displacing the adjacent particle the\nfirst particle comes back to its original\nposition. This pr ocess continues in the\nmedium till the sound r eaches your ear . The\ndisturbance created by a source of  sound in\nthe medium travels through the medium and\nnot the particles of the medium.\nA wave is a disturbance that moves\nthrough a medium when the particles of the\nmedium set neighbouring particles into\nmotion. They in tur n produce similar motion\nin others. The particles of the medium do not\nmove forwar d themselves, but the\ndisturbance is carried forwar d. This is what\nhappens during pr opagation of sound in a\nmedium, hence sound can be visualised as a\nwave. Sound waves are characterised by the\nmotion of particles in the medium and ar e\ncalled mechanical waves.\nAir is the most common medium thr ough\nwhich sound travels. When a vibrating object\nmoves forward, it pushes and compresses the\nair in front of it creating a region of high\npressur e. This r egion is called a compr ession\n(C), as shown in Fig. 11.4. This compression\nstarts to move away from the vibrating object.\nWhen the vibrating object moves backwar ds,\nit creates a r egion of low pr essur e called\nrarefaction (R), as shown in Fig. 11.4. As the\nobject moves back and forth rapidly, a series\nof compressions and rarefactions is created in\nthe air . These make the sound wave thatFig. 11.3: Both the prongs of the vibrating tuning\nfork dipped in water\nFrom the above activities what do you\nconclude? Can you pr oduce sound without\na vibrating object?\nIn the above activities we have pr oduced\nsound by striking the tuning fork. W e can\nalso pr oduce sound by plucking, scratching,\nrubbing, blowing or shaking dif ferent objects.\nAs per the above activities what do we do to\nthe objects? W e set the objects vibrating and\nproduce sound. V ibration means a kind of\nrapid to and fr o motion of an object. The\nsound of the human voice is pr oduced due\nto vibrations in the vocal cor ds. When a bir d\nflaps its wings, do you hear any sound? Think\nhow the buzzing sound accompanying a bee\nis produced. A str etched rubber band when\nplucked vibrates and produces sound. If you\nhave never done this, then do it and observe\nthe vibration of the str etched rubber band.\nActivity _____________ 11.3\n•Make a list of different types of\nmusical instruments and discuss\nwith your friends which part of the\ninstrument vibrates to produce\nsound.\n11.2Propagation of Sound\nSound is pr oduced by vibrating objects. The\nmatter or substance thr ough which sound\nis transmitted is called a medium. It can be\nsolid, liquid or gas. Sound moves thr ough a\nmedium from the point of generation to the\nlistener . When an object vibrates, it sets the\nparticles of the medium ar ound it vibrating.\nThe particles do not travel all the way fromFig. 11.4: A vibrating object creating a series of\ncompr essions (C) and rar efactions (R) in\nthe medium.\nRationalised 2023-24\n\nQuestion: What is linear sound?\nHelpful Answer: Linear sound is a type of sound that travels in a straight line through a medium. It is characterized by the fact that the particles of the medium move in a straight line, with no deviation from the path of the sound wave. Linear sound is produced by vibrating objects that are parallel to the direction of sound propagation. Examples of linear sound include the sound of a whistle or the sound of a violin string being plucked.\n\nRetrieved Document 1:\n SOUND 131How the brain interprets the frequency\nof an emitted sound is called its pitch. The\nfaster the vibration of the source, the\nhigher is the frequency and the higher is\nthe pitch, as shown in Fig. 11.7. Thus, a\nhigh pitch sound corresponds to more\nnumber of compressions and rarefactions\npassing a fixed point per unit time.\nObjects of different sizes and conditions\nvibrate at different frequencies to produce\nsounds of different pitch.\nThe magnitude of the maximum\ndisturbance in the medium on either side of\nthe mean value is called the amplitude of the\nwave. It is usually represented by the letter A,as shown in Fig. 11.6(c). For sound its unit\nwill be that of density or pressure.\nThe loudness or softness of a sound is\ndetermined basically by its amplitude. The\namplitude of the sound wave depends upon\nthe force with which an object is made to\nvibrate. If we strike a table lightly, we hear a\nsoft sound because we produce a sound wavedensity of the medium oscillates between a\nmaximum value and a minimum value. The\nchange in density from the maximum value\nto the minimum value, then again to the\nmaximum value, makes one complete\noscillation. The number of such oscillations\nper unit time is the frequency of the sound\nwave. If we can count the number of the\ncompressions or rarefactions that cross us\nper unit time, we will get the frequency of\nthe sound wave. It is usually represented by\nν (Greek letter , nu). Its SI unit is hertz\n(symbol, Hz).\nThe time taken by two consecutive\ncompressions or rarefactions to cross a fixed\npoint is called the time period of the wave. In\nother words, we can say that the time taken\nfor one complete oscillation is called the time\nperiod of the sound wave. It is represented by\nthe symbol T. Its SI unit is second (s).\nFrequency and time period are related as\nfollows:\n A violin and a flute may both be played at\nthe same time in an orchestra. Both sounds\ntravel through the same medium, that is, air\nand arrive at our ear at the same time. Both\nsounds travel at the same speed irrespective\nof the source. But the sounds we receive are\ndifferent. This is due to the different\ncharacteristics associated with the sound.\nPitch is one of the characteristics.=1vTFig. 11.7:  Low pitch sound has low frequency and\nhigh pitch of sound has high frequency.\nFig. 11.8: Soft sound has small amplitude and\nlouder sound has large amplitude.\nRationalised 2023-24\n\nRetrieved Document 2:\n SCIENCE 128the vibrating object to the ear . A particle of\nthe medium in contact with the vibrating\nobject is first displaced fr om its equilibrium\nposition. It then exerts a for ce on the adjacent\nparticle. As a r esult of which the adjacent\nparticle gets displaced fr om its position of\nrest. After displacing the adjacent particle the\nfirst particle comes back to its original\nposition. This pr ocess continues in the\nmedium till the sound r eaches your ear . The\ndisturbance created by a source of  sound in\nthe medium travels through the medium and\nnot the particles of the medium.\nA wave is a disturbance that moves\nthrough a medium when the particles of the\nmedium set neighbouring particles into\nmotion. They in tur n produce similar motion\nin others. The particles of the medium do not\nmove forwar d themselves, but the\ndisturbance is carried forwar d. This is what\nhappens during pr opagation of sound in a\nmedium, hence sound can be visualised as a\nwave. Sound waves are characterised by the\nmotion of particles in the medium and ar e\ncalled mechanical waves.\nAir is the most common medium thr ough\nwhich sound travels. When a vibrating object\nmoves forward, it pushes and compresses the\nair in front of it creating a region of high\npressur e. This r egion is called a compr ession\n(C), as shown in Fig. 11.4. This compression\nstarts to move away from the vibrating object.\nWhen the vibrating object moves backwar ds,\nit creates a r egion of low pr essur e called\nrarefaction (R), as shown in Fig. 11.4. As the\nobject moves back and forth rapidly, a series\nof compressions and rarefactions is created in\nthe air . These make the sound wave thatFig. 11.3: Both the prongs of the vibrating tuning\nfork dipped in water\nFrom the above activities what do you\nconclude? Can you pr oduce sound without\na vibrating object?\nIn the above activities we have pr oduced\nsound by striking the tuning fork. W e can\nalso pr oduce sound by plucking, scratching,\nrubbing, blowing or shaking dif ferent objects.\nAs per the above activities what do we do to\nthe objects? W e set the objects vibrating and\nproduce sound. V ibration means a kind of\nrapid to and fr o motion of an object. The\nsound of the human voice is pr oduced due\nto vibrations in the vocal cor ds. When a bir d\nflaps its wings, do you hear any sound? Think\nhow the buzzing sound accompanying a bee\nis produced. A str etched rubber band when\nplucked vibrates and produces sound. If you\nhave never done this, then do it and observe\nthe vibration of the str etched rubber band.\nActivity _____________ 11.3\n•Make a list of different types of\nmusical instruments and discuss\nwith your friends which part of the\ninstrument vibrates to produce\nsound.\n11.2Propagation of Sound\nSound is pr oduced by vibrating objects. The\nmatter or substance thr ough which sound\nis transmitted is called a medium. It can be\nsolid, liquid or gas. Sound moves thr ough a\nmedium from the point of generation to the\nlistener . When an object vibrates, it sets the\nparticles of the medium ar ound it vibrating.\nThe particles do not travel all the way fromFig. 11.4: A vibrating object creating a series of\ncompr essions (C) and rar efactions (R) in\nthe medium.\nRationalised 2023-24\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create RetrievalQA instance\nstart_time = time.time()  # Start time tracking for QA chain creation\nqa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))\n\n# Record the time taken to create the QA chain\nqa_creation_time = time.time() - start_time\nprint(f\"Time taken to create QA chain: {qa_creation_time:.2f} seconds\")\n\n# Define your query\nquery = \"What is linear sound\"\n\n# Run the query and get the answer\nstart_time = time.time()  # Start time tracking for running the query\nresponse = qa.run(query)\n\n# Record the time taken to run the query\nquery_time = time.time() - start_time\nprint(f\"Time taken to run the query: {query_time:.2f} seconds\")\n\n# Output the response\nprint(\"Query Response:\")\nprint(response)","metadata":{},"execution_count":null,"outputs":[]}]}